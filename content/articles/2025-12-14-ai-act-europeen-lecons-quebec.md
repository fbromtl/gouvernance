---
title: "Le Règlement européen sur l'IA (AI Act) en 2026 : leçons concrètes pour le Québec"
slug: ai-act-europeen-lecons-quebec
date: "2025-12-14"
category: veille
excerpt: "L'AI Act européen entre dans sa phase décisive en 2026. Approche par les risques, interdictions, obligations pour les systèmes à haut risque : les leçons concrètes que le Québec peut en tirer."
cover: /images/articles/ai-act-lecons.jpg
author: florian-brobst
featured: false
tags: "AI Act, Europe, réglementation, classification des risques, conformité, effet Bruxelles"
---

## L'AI Act entre dans sa phase décisive

Le Règlement européen sur l'intelligence artificielle est entré dans sa phase d'application la plus significative. Après l'entrée en vigueur des obligations de littératie en IA en février 2025 et des règles de gouvernance et obligations pour les modèles d'IA à usage général en août 2025, l'année 2026 voit l'application des règles de transparence et, progressivement, des obligations pour les systèmes à haut risque. La Commission européenne a toutefois proposé en novembre 2025 de reporter l'échéance des systèmes à haut risque à décembre 2027 au plus tard, reconnaissant la complexité de la mise en conformité.

Pour le Québec, l'AI Act n'est pas seulement un règlement étranger : c'est un laboratoire réglementaire dont les leçons sont directement exploitables.

## L'approche par les risques : un modèle transposable

L'architecture fondée sur le risque de l'AI Act offre un cadre logique que le Québec pourrait adapter. La classification en quatre niveaux — risque inacceptable (interdit), haut risque (obligations strictes), risque limité (transparence) et risque minimal (libre) — permet de concentrer les obligations réglementaires là où les enjeux sont les plus critiques, sans imposer de fardeau disproportionné aux applications à faible risque.

Pour le Québec, une classification adaptée pourrait tenir compte des spécificités locales. Les systèmes d'IA utilisés dans le réseau de la santé québécois, dans les services sociaux, dans l'éducation et dans la justice pourraient être classés comme à haut risque, avec des obligations proportionnées. Les systèmes de recommandation de contenu et les agents conversationnels pourraient relever de la catégorie de risque limité, avec des obligations de transparence.

## Les interdictions : tracer les lignes rouges

L'AI Act interdit certaines pratiques jugées inacceptables : la notation sociale (social scoring), la manipulation subliminale, l'exploitation de vulnérabilités de personnes vulnérables et certaines formes de reconnaissance faciale en temps réel dans les espaces publics. Ces interdictions reflètent des choix de valeurs fondamentaux sur les limites de l'utilisation de l'IA.

Le Québec pourrait s'inspirer de cette approche pour définir ses propres lignes rouges, en tenant compte de ses valeurs et de son cadre constitutionnel. La Charte des droits et libertés de la personne offre déjà un socle pour justifier l'interdiction de certaines applications d'IA particulièrement attentatoires aux droits fondamentaux.

## Les obligations pour les systèmes à haut risque

Les exigences imposées aux systèmes d'IA à haut risque par l'AI Act constituent un référentiel détaillé dont les organisations québécoises peuvent s'inspirer, même en l'absence de législation locale équivalente. Ces exigences incluent un système de gestion des risques tout au long du cycle de vie, des critères de qualité et de gouvernance des données d'entraînement, une documentation technique exhaustive, la tenue de registres et la journalisation des opérations, la transparence envers les utilisateurs, des mesures de surveillance humaine, et des exigences de précision, de robustesse et de cybersécurité.

Les entreprises québécoises qui exportent vers l'Europe ou qui traitent des données de citoyens européens sont directement soumises à ces obligations, en raison de la portée extraterritoriale du règlement. Mais même les organisations qui n'opèrent qu'au Québec gagneraient à adopter ces bonnes pratiques, qui constituent un standard de référence international.

## Les leçons des premières difficultés d'application

Les premiers mois d'application de l'AI Act ont révélé des défis qui offrent des leçons précieuses pour le Québec.

La complexité de la classification des systèmes s'est avérée plus grande que prévu. Déterminer si un système d'IA relève de la catégorie à haut risque exige une analyse détaillée de son contexte d'utilisation, ce qui génère une incertitude juridique pour les organisations. Le Québec devrait veiller à définir des critères de classification clairs et à fournir des lignes directrices pratiques.

Le coût de la conformité pèse lourdement sur les PME. Les exigences de documentation, d'évaluation et de surveillance représentent un investissement significatif. Le Québec devrait prévoir des mécanismes de soutien pour les petites organisations, comme des guides simplifiés, des outils en libre accès et des programmes d'accompagnement.

La coordination entre les autorités nationales de surveillance reste un défi. Chaque État membre de l'UE désigne ses propres autorités compétentes, ce qui peut mener à des interprétations divergentes. Le Québec, en concevant son propre cadre, a l'avantage de pouvoir centraliser la surveillance auprès d'un nombre limité d'organismes.

## L'effet Bruxelles et ses implications pour le Québec

L'AI Act exerce un « effet Bruxelles » — une influence normative qui dépasse les frontières de l'UE. Les entreprises technologiques internationales tendent à aligner leurs pratiques sur les normes les plus exigeantes pour simplifier leur conformité mondiale. Les entreprises québécoises qui adoptent les standards de l'AI Act se positionnent donc avantageusement pour opérer dans un environnement réglementaire mondial convergent.

Cet effet représente aussi une opportunité stratégique pour le Québec. En alignant son propre cadre sur les principes de l'AI Act tout en l'adaptant à ses spécificités, le Québec faciliterait les échanges commerciaux avec l'Europe, attirerait des entreprises soucieuses de conformité et renforcerait sa crédibilité internationale en matière de gouvernance de l'IA.

## Recommandations

Le Québec devrait étudier en profondeur l'expérience de mise en œuvre de l'AI Act pour en tirer des enseignements applicables, engager un dialogue avec les autorités européennes pour faciliter l'interopérabilité des cadres, développer un cadre de classification des risques adapté au contexte québécois, et prévoir des mesures de soutien pour les PME dans leur démarche de conformité.

## Conclusion

L'AI Act européen est le laboratoire réglementaire le plus ambitieux au monde en matière d'IA. Ses succès et ses difficultés offrent au Québec un terrain d'apprentissage inestimable pour concevoir son propre modèle de gouvernance. L'enjeu n'est pas de copier le règlement européen, mais d'en extraire les principes et les mécanismes les plus pertinents pour construire un cadre québécois adapté, efficace et à la hauteur des défis posés par l'intelligence artificielle.
